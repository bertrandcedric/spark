{"paragraphs":[{"text":"%dep\nz.reset()\nz.addRepo(\"Spark Packages Repo\").url(\"http://dl.bintray.com/spark-packages/maven\")\nz.load(\"com.databricks:spark-csv_2.11:1.3.0\")","dateUpdated":"Feb 19, 2016 1:48:16 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1455889187997_369435674","id":"20160219-133947_1500763685","result":{"code":"ERROR","type":"TEXT","msg":"Must be used before SparkInterpreter (%spark) initialized\nHint: put this paragraph before any Spark code and restart Zeppelin/Interpreter"},"dateCreated":"Feb 19, 2016 1:39:47 PM","dateStarted":"Feb 19, 2016 1:48:16 PM","dateFinished":"Feb 19, 2016 1:48:16 PM","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:322"},{"text":"val df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"src/main/resources/data/home_data.csv\").cache()\n\ndf.printSchema()\n\nval zipcode = df.select(\"price\", \"zipcode\").groupBy(\"zipcode\").mean(\"price\").sort(desc(\"avg(price)\")).show()\n","dateUpdated":"Feb 19, 2016 1:48:16 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1455888449480_1085777950","id":"20160219-132729_1890674446","result":{"code":"ERROR","type":"TEXT","msg":"java.lang.ClassNotFoundException: Failed to find data source: com.databricks.spark.csv. Please find packages at http://spark-packages.org\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$.lookupDataSource(ResolvedDataSource.scala:77)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:102)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:119)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:109)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:50)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:55)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:57)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:59)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:61)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:63)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:65)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:69)\n\tat $iwC$$iwC$$iwC$$iwC.<init>(<console>:71)\n\tat $iwC$$iwC$$iwC.<init>(<console>:73)\n\tat $iwC$$iwC.<init>(<console>:75)\n\tat $iwC.<init>(<console>:77)\n\tat <init>(<console>:79)\n\tat .<init>(<console>:83)\n\tat .<clinit>(<console>)\n\tat .<init>(<console>:7)\n\tat .<clinit>(<console>)\n\tat $print(<console>)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpretInput(SparkInterpreter.java:709)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:673)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:666)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:295)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:171)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.ClassNotFoundException: com.databricks.spark.csv.DefaultSource\n\tat scala.tools.nsc.interpreter.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:83)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$$anonfun$4$$anonfun$apply$1.apply(ResolvedDataSource.scala:62)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$$anonfun$4$$anonfun$apply$1.apply(ResolvedDataSource.scala:62)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$$anonfun$4.apply(ResolvedDataSource.scala:62)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$$anonfun$4.apply(ResolvedDataSource.scala:62)\n\tat scala.util.Try.orElse(Try.scala:82)\n\tat org.apache.spark.sql.execution.datasources.ResolvedDataSource$.lookupDataSource(ResolvedDataSource.scala:62)\n\t... 46 more\n\n"},"dateCreated":"Feb 19, 2016 1:27:29 PM","dateStarted":"Feb 19, 2016 1:48:16 PM","dateFinished":"Feb 19, 2016 1:48:17 PM","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:323"},{"text":"import org.apache.commons.io.IOUtils\nimport java.io.File\nimport java.nio.charset.Charset\n\nval bankText = sc.textFile(\"/zeppelin_notebooks/people-example.csv\")\n\ncase class People(firstname: String, lastname: String, country: String, age: Integer)\n\nval bank = bankText.map(s => s.split(\",\")).map(\n    s => People(s(0), s(1), s(2), s(3).toInt)\n).toDF()\n\nbank.registerTempTable(\"bank\")\n","dateUpdated":"Feb 19, 2016 1:48:16 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1455889475031_1801100011","id":"20160219-134435_1757436939","result":{"code":"SUCCESS","type":"TEXT","msg":"import org.apache.commons.io.IOUtils\nimport java.io.File\nimport java.nio.charset.Charset\nbankText: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[11] at textFile at <console>:57\ndefined class People\nbank: org.apache.spark.sql.DataFrame = [firstname: string, lastname: string, country: string, age: int]\n"},"dateCreated":"Feb 19, 2016 1:44:35 PM","dateStarted":"Feb 19, 2016 1:48:16 PM","dateFinished":"Feb 19, 2016 1:48:19 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:324"},{"text":"%sql \nselect *\nfrom bank ","dateUpdated":"Feb 19, 2016 1:48:16 PM","config":{"colWidth":12,"editorMode":"ace/mode/sql","graph":{"mode":"pieChart","height":300,"optionOpen":true,"keys":[{"name":"country","index":2,"aggr":"sum","$$hashKey":"object:2821"}],"values":[{"name":"country","index":2,"aggr":"count","$$hashKey":"object:2823"}],"groups":[],"scatter":{"xAxis":{"name":"firstname","index":0,"aggr":"sum"},"yAxis":{"name":"lastname","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1455888449483_1086162699","id":"20160219-132729_1504342862","result":{"code":"SUCCESS","type":"TABLE","msg":"firstname\tlastname\tcountry\tage\n\"Bob\"\t\"Smith\"\t\"United States\"\t24\n\"Alice\"\t\"Williams\"\t\"Canada\"\t23\n\"Malcolm\"\t\"Jone\"\t\"England\"\t22\n\"Felix\"\t\"Brown\"\t\"USA\"\t23\n\"Alex\"\t\"Cooper\"\t\"Poland\"\t23\n\"Tod\"\t\"Campbell\"\t\"United States\"\t22\n\"Derek\"\t\"Ward\"\t\"Switzerland\"\t25\n","comment":"","msgTable":[[{"key":"lastname","value":"\"Bob\""},{"key":"lastname","value":"\"Smith\""},{"key":"lastname","value":"\"United States\""},{"key":"lastname","value":"24"}],[{"key":"country","value":"\"Alice\""},{"key":"country","value":"\"Williams\""},{"key":"country","value":"\"Canada\""},{"key":"country","value":"23"}],[{"key":"age","value":"\"Malcolm\""},{"key":"age","value":"\"Jone\""},{"key":"age","value":"\"England\""},{"key":"age","value":"22"}],[{"value":"\"Felix\""},{"value":"\"Brown\""},{"value":"\"USA\""},{"value":"23"}],[{"value":"\"Alex\""},{"value":"\"Cooper\""},{"value":"\"Poland\""},{"value":"23"}],[{"value":"\"Tod\""},{"value":"\"Campbell\""},{"value":"\"United States\""},{"value":"22"}],[{"value":"\"Derek\""},{"value":"\"Ward\""},{"value":"\"Switzerland\""},{"value":"25"}]],"columnNames":[{"name":"firstname","index":0,"aggr":"sum","$$hashKey":"object:510"},{"name":"lastname","index":1,"aggr":"sum","$$hashKey":"object:511"},{"name":"country","index":2,"aggr":"sum","$$hashKey":"object:512"},{"name":"age","index":3,"aggr":"sum","$$hashKey":"object:513"}],"rows":[["\"Bob\"","\"Smith\"","\"United States\"","24"],["\"Alice\"","\"Williams\"","\"Canada\"","23"],["\"Malcolm\"","\"Jone\"","\"England\"","22"],["\"Felix\"","\"Brown\"","\"USA\"","23"],["\"Alex\"","\"Cooper\"","\"Poland\"","23"],["\"Tod\"","\"Campbell\"","\"United States\"","22"],["\"Derek\"","\"Ward\"","\"Switzerland\"","25"]]},"dateCreated":"Feb 19, 2016 1:27:29 PM","dateStarted":"Feb 19, 2016 1:48:17 PM","dateFinished":"Feb 19, 2016 1:28:49 PM","status":"RUNNING","progressUpdateIntervalMs":500,"$$hashKey":"object:325"},{"dateUpdated":"Feb 19, 2016 1:48:16 PM","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1455888449484_1084238954","id":"20160219-132729_1646429807","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"Feb 19, 2016 1:27:29 PM","dateStarted":"Feb 19, 2016 1:28:20 PM","dateFinished":"Feb 19, 2016 1:28:21 PM","status":"PENDING","progressUpdateIntervalMs":500,"$$hashKey":"object:326"}],"name":"Getting started Zeppelin","id":"2BBBDDYXA","angularObjects":{"2BAY42QGQ":[],"2BDD2WGZN":[],"2BBNWZHSA":[],"2BDYX852B":[],"2BEEMZJM9":[],"2BE8R7952":[],"2BDCCHN72":[],"2BBJ4R3CD":[],"2BCDCD19N":[],"2BEVA9BAV":[],"2BBJRH8UZ":[],"2BDW1XE21":[],"2BE2QHURM":[],"2BDEKU8J4":[],"2BBQ2BECN":[]},"config":{"looknfeel":"default"},"info":{}}